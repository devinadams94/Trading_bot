================================================================================
GPU CLOUD TRAINING - ONE-LINER COMMANDS
Trading Bot - Enhanced CLSTM-PPO
================================================================================

üìã COPY-PASTE READY COMMANDS

================================================================================
üöÄ PRODUCTION TRAINING (RECOMMENDED)
================================================================================

tmux new-session -d -s training "python train_enhanced_clstm_ppo.py --num_episodes 5000 --num_gpus -1 --enable-multi-leg --use-ensemble --num-ensemble-models 3 --early-stopping-patience 500 --checkpoint-dir checkpoints/production_run --resume" && echo "‚úÖ Training started! Monitor: tmux attach -t training"

Time: 12-24 hours on 4x A100
Cost: $60-300
Expected Sharpe: 2.0-3.0

================================================================================
üß™ VALIDATION TEST (QUICK)
================================================================================

python train_enhanced_clstm_ppo.py --num_episodes 100 --num_gpus 1 --enable-multi-leg --checkpoint-dir checkpoints/validation_test --fresh-start

Time: 30-60 minutes
Cost: $0.50-3
Purpose: Verify setup

================================================================================
‚ö° MAXIMUM PERFORMANCE (8 GPUs)
================================================================================

tmux new-session -d -s training "python train_enhanced_clstm_ppo.py --num_episodes 10000 --num_gpus 8 --enable-multi-leg --use-ensemble --num-ensemble-models 5 --early-stopping-patience 1000 --checkpoint-dir checkpoints/max_performance --resume" && echo "‚úÖ Training started! Monitor: tmux attach -t training"

Time: 24-48 hours on 8x A100
Cost: $150-600
Expected Sharpe: 2.5-3.5+

================================================================================
üí∞ BUDGET TRAINING (1 GPU)
================================================================================

tmux new-session -d -s training "python train_enhanced_clstm_ppo.py --num_episodes 3000 --num_gpus 1 --enable-multi-leg --early-stopping-patience 300 --checkpoint-dir checkpoints/budget_run --resume" && echo "‚úÖ Training started! Monitor: tmux attach -t training"

Time: 8-12 hours on 1x A100
Cost: $4-36
Expected Sharpe: 1.5-2.5

================================================================================
üîß SETUP COMMANDS
================================================================================

# Install dependencies
pip install -r requirements.txt

# Verify GPU setup
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPUs: {torch.cuda.device_count()}')"

# Create directories
mkdir -p logs checkpoints/production_run

# Check GPU memory
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv

================================================================================
üìä MONITORING COMMANDS
================================================================================

# Attach to training session
tmux attach -t training

# Detach from tmux (while inside)
Ctrl+B, then D

# View logs in real-time
tail -f logs/training_*.log

# Monitor GPU usage
watch -n 1 nvidia-smi

# Better GPU monitoring
nvtop

# Check training progress
grep 'Episode' logs/training_*.log | tail -20

# Check best metrics
grep 'New best' logs/training_*.log

================================================================================
üõ†Ô∏è TROUBLESHOOTING
================================================================================

# Resume training after interruption
python train_enhanced_clstm_ppo.py --resume

# Start fresh (ignore checkpoints)
python train_enhanced_clstm_ppo.py --fresh-start

# Kill training session
tmux kill-session -t training

# List all tmux sessions
tmux ls

# Increase NCCL timeout (if multi-GPU timeout)
export NCCL_TIMEOUT=7200

================================================================================
üí° INTERACTIVE MENU
================================================================================

# Run interactive menu
./QUICK_START_COMMANDS.sh

# Or run specific command
./QUICK_START_COMMANDS.sh production
./QUICK_START_COMMANDS.sh validation
./QUICK_START_COMMANDS.sh max
./QUICK_START_COMMANDS.sh budget
./QUICK_START_COMMANDS.sh verify

================================================================================
üéØ RECOMMENDED WORKFLOW
================================================================================

1. SETUP (5 minutes)
   pip install -r requirements.txt
   python -c "import torch; print(torch.cuda.is_available())"

2. VALIDATION (30-60 minutes, $0.50-3)
   python train_enhanced_clstm_ppo.py --num_episodes 100 --num_gpus 1 --enable-multi-leg --fresh-start

3. PRODUCTION (12-24 hours, $60-300)
   tmux new-session -d -s training "python train_enhanced_clstm_ppo.py --num_episodes 5000 --num_gpus -1 --enable-multi-leg --use-ensemble --num-ensemble-models 3 --resume"

4. MONITOR
   tmux attach -t training
   tail -f logs/training_*.log

================================================================================
üí∞ COST ESTIMATES
================================================================================

Provider          | Instance         | GPUs      | Cost/hr | 5000 episodes
------------------|------------------|-----------|---------|---------------
Lambda Labs       | 4x A100 (40GB)   | 4x A100   | $5      | $60-120
Vast.ai           | 4x RTX 4090      | 4x 4090   | $1-2    | $12-48
AWS               | p3.8xlarge       | 4x V100   | $12     | $144-288
GCP               | a2-highgpu-4g    | 4x A100   | $15     | $180-360
Azure             | NC24s_v3         | 4x V100   | $12     | $144-288

RECOMMENDED: Lambda Labs 4x A100 ($5/hr) - Best price/performance üèÜ

================================================================================
üìà EXPECTED RESULTS
================================================================================

After 1000 episodes (~4-6 hours):
  - Cumulative Return: 15-25%
  - Sharpe Ratio: 1.2-1.8
  - Win Rate: 52-58%

After 3000 episodes (~12-18 hours):
  - Cumulative Return: 30-50%
  - Sharpe Ratio: 1.8-2.5
  - Win Rate: 58-65%

After 5000 episodes (~20-30 hours):
  - Cumulative Return: 50-80%
  - Sharpe Ratio: 2.0-3.0+
  - Win Rate: 62-70%

================================================================================
‚úÖ PRE-FLIGHT CHECKLIST
================================================================================

[ ] GPU cloud instance launched
[ ] Repository cloned
[ ] Dependencies installed (pip install -r requirements.txt)
[ ] .env file configured with Alpaca API keys
[ ] GPU availability verified (nvidia-smi)
[ ] PyTorch CUDA verified (python -c "import torch; print(torch.cuda.is_available())")
[ ] Tmux installed (sudo apt-get install tmux)
[ ] Training command ready to run

================================================================================
üöÄ READY TO TRAIN!
================================================================================

Just copy-paste the PRODUCTION TRAINING command above and you're good to go!

Questions? Check GPU_CLOUD_TRAINING_GUIDE.md for detailed documentation.

================================================================================

